# GTE-Qwen2-7B-Instruct Isolated Embedding Model Configuration

embedding_model:
  name: "gte-Qwen2-7B-instruct"
  path: "embedding_models/gte-Qwen2-7B-instruct"
  type: "gte"
  batch_size: 8
  max_length: 8192         # Can handle up to 32k, using 8192 for efficiency
  trust_remote_code: true
  additional_params: {}

  # Fine-grained evaluation settings
  fine_grained:
    enabled: true           # Enable fine-grained embedding matching
    chunking_method: "nltk" # Use NLTK sentence tokenizer for chunking

processing:
  device: "cuda:0"
  clear_cache_interval: 25
  progress_interval: 10

data_paths:
  # Use relative paths - will be resolved from base directory
  ground_truth_file: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/tmp/ground_truth-subset/clip_cc_dataset.json"
  predictions_dir: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/tmp/models-subset"
  results_base_dir: "results"

# Text generation models to evaluate
models_to_evaluate:
  - "internvl"
  - "llava_next_video"
  - "llava_one_vision"
  - "longva"
  - "longvu"
  - "minicpm"
  - "mplug"
  - "oryx"
  - "Qwen2.5-32B"
  - "Qwen2.5-72B"
  - "sharegpt4"
  - "timechat"
  - "ts_llava"
  - "videochatflash"
  - "videollama3"
  - "video_xl"
  - "vilamp"

logging:
  level: "INFO"
  log_prefix: "gte_evaluation"
