# NV-Embed Isolated Decoder Configuration

decoder:
  name: "nv-embed"
  path: "decoder_models/nv-embed"
  type: "nvembed"
  batch_size: 8             # Default from NV-Embed repo
  max_length: 32768         # Default max context length
  device_map: "auto"
  trust_remote_code: true
  additional_params:
    instruction_for_retrieval: ""

  # Fine-grained evaluation settings
  fine_grained:
    enabled: true           # Enable fine-grained embedding matching
    chunking_method: "nltk" # Use NLTK sentence tokenizer for chunking

processing:
  device: "cuda:0"
  clear_cache_interval: 25
  progress_interval: 10

data_paths:
  # Use relative paths - will be resolved from base directory
  ground_truth_file: "data/ground_truth/clip_cc_dataset.json"
  # ground_truth_file: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/tmp/ground_truth-subset/clip_cc_dataset.json"
  predictions_dir: "data/models"
  # predictions_dir: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/tmp/models-subset"
  results_base_dir: "results"

# Text generation models to evaluate
models_to_evaluate:

  - "videollama3"


logging:
  level: "INFO"
  log_dir: "results/decoders/logs/nv-embed"
  log_prefix: "nv_embed_evaluation"
