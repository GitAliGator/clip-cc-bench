# E5-Mistral-7B-Instruct Isolated Encoder Configuration

encoder:
  name: "e5-mistral-7b-instruct"
  path: "encoder_models/e5-mistral-7b-instruct"
  type: "e5_mistral"
  batch_size: 8                  # Conservative for large 7B model
  max_length: 4096
  device_map: "auto"
  trust_remote_code: true
  additional_params:
    model_type: "e5_mistral"
    instruction_for_retrieval: "Instruct: Given a web search query, retrieve relevant passages that answer the query\nQuery: "

processing:
  use_gpu: true
  device: "cuda:0"
  clear_cache_interval: 20      # More frequent cache clearing for large model
  force_gc_interval: 40
  save_intermediate_results: true
  progress_interval: 10

data_paths:
  # Use relative paths - will be resolved from base directory
  ground_truth_file: "data/ground_truth/clip_cc_dataset.json"
  predictions_dir: "data/models"
  results_base_dir: "results"

# Text generation models to evaluate
models_to_evaluate:
  - "internvl"
  - "llava_next_video"
  - "llava_one_vision"
  - "longva"
  - "longvu"
  - "minicpm"
  - "mplug"
  - "oryx"
  - "sharegpt4"
  - "timechat"
  - "ts_llava"
  - "videochatflash"
  - "videollama3"
  - "video_xl"
  - "vilamp"

logging:
  level: "INFO"
  log_dir: "results/encoders/logs/e5-mistral-7b-instruct"
  log_prefix: "e5_mistral_evaluation"

embedding:
  cache_embeddings: true
  normalize_text: false
  truncate_strategy: "none"
  similarity_metric: "cosine"
  normalize_embeddings: true

# Metrics to compute
metrics:
  - "cosine_similarity"
  - "normalized_cosine"