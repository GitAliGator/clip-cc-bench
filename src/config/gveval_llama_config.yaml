# G-VEval LLaMA Configuration (Standalone - No Dependencies)
# Replicates G-VEval methodology using local LLaMA inference

gveval_llama:
  # Model configuration - UPGRADED TO 70B
  model_path: "/home/jacks.local/mali9292/LLMs/Llama-3.1-70B-Instruct/"
  torch_dtype: "bfloat16"
  device_map: "auto"            # Auto-distribute across 2x H100 GPUs
  trust_remote_code: true
  local_files_only: true
  
  # G-VEval specific settings
  evaluation_mode: "ref-only"
  rubric_type: "accr"
  
  # Generation parameters optimized for 70B model evaluation
  temperature: 0.05             # Lower temperature for 70B model stability
  max_new_tokens: 1024          # Sufficient for detailed evaluation
  min_new_tokens: 100           # Ensure sufficient reasoning
  do_sample: true
  
  # Prompt configuration
  prompt_template_path: "prompts/vid/accr/ref-only.txt"
  
  # Scoring configuration (G-VEval uses 0-100 scale)
  score_range: [0, 100]
  criteria: ["accuracy", "completeness", "conciseness", "relevance"]

# Processing settings - MEMORY OPTIMIZED SEQUENTIAL
processing:
  batch_size: 1                 # Single sample processing for quality
  max_workers: 1                # Sequential processing for 70B model (memory safety)
  checkpoint_interval: 10       # Progress checkpoints
  save_intermediate_results: true
  
  # Parallel processing settings (DISABLED for memory optimization)
  model_level_parallelization: false   # Disabled: 70B model requires full GPU memory
  gpu_assignment_strategy: "auto"      # Auto-assign models to GPUs

# Data paths (absolute paths for clip-cc-bench directory)
data_paths:
  ground_truth_file: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/clip-cc-bench/data/ground_truth/clip_cc_dataset.json"
  predictions_dir: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/clip-cc-bench/data/models"
  results_base_dir: "/mmfs2/home/jacks.local/mali9292/aaai_student_abstract/clip-cc-bench/results"

# Models to evaluate (test subset - only models with available data)
models_to_evaluate:
  - "Qwen2.5-72B"
  - "Qwen2.5-32B" 

# Logging configuration
logging:
  level: "INFO"
  log_dir: "results/g-veval/logs"
  log_prefix: "gveval_llama_evaluation"